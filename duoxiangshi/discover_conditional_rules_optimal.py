import pandas as pd
from sklearn.tree import DecisionTreeRegressor, export_text
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
import numpy as np
import warnings
import argparse
from itertools import combinations
import time
warnings.filterwarnings('ignore')

class OptimalConditionalRuleDiscoverer:
    """
    ä¼˜åŒ–ç‰ˆçš„æ¡ä»¶å¤šé¡¹å¼è§„åˆ™å‘ç°å™¨
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. æ™ºèƒ½ç‰¹å¾ç»„åˆç©·ä¸¾
    2. äº¤å‰éªŒè¯è¯„ä¼°æœ€ä¼˜ç»„åˆ
    3. æ”¯æŒç¦»æ•£å‹åˆ†æ®µç‰¹å¾
    4. åŠ¨æ€ç‰¹å¾åˆ†é…ä¼˜åŒ–
    """
    
    def __init__(self, max_depth=3, min_samples_leaf=50, cv_folds=3, 
                 max_combinations=100, enable_exhaustive_search=True):
        """
        åˆå§‹åŒ–å‚æ•°
        
        Args:
            max_depth: å†³ç­–æ ‘æœ€å¤§æ·±åº¦
            min_samples_leaf: å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
            cv_folds: äº¤å‰éªŒè¯æŠ˜æ•°
            max_combinations: æœ€å¤§å°è¯•çš„ç‰¹å¾ç»„åˆæ•°ï¼ˆé˜²æ­¢è®¡ç®—é‡è¿‡å¤§ï¼‰
            enable_exhaustive_search: æ˜¯å¦å¯ç”¨ç©·ä¸¾æœç´¢
        """
        self.max_depth = max_depth
        self.min_samples_leaf = min_samples_leaf
        self.cv_folds = cv_folds
        self.max_combinations = max_combinations
        self.enable_exhaustive_search = enable_exhaustive_search
        self.discovered_rules = []
        self.best_configuration = None
        self.label_encoders = {}  # å­˜å‚¨åˆ†ç±»ç‰¹å¾çš„ç¼–ç å™¨
        self.categorical_features = []  # å­˜å‚¨åˆ†ç±»ç‰¹å¾åˆ—è¡¨
        
    def _identify_feature_types(self, data, target_col):
        """
        è¯†åˆ«æ•°å€¼å‹å’Œåˆ†ç±»å‹ç‰¹å¾
        
        Returns:
            numeric_features: æ•°å€¼å‹ç‰¹å¾åˆ—è¡¨
            categorical_features: åˆ†ç±»å‹ç‰¹å¾åˆ—è¡¨
            all_split_candidates: æ‰€æœ‰å¯ç”¨ä½œåˆ†æ®µçš„ç‰¹å¾
        """
        # æ’é™¤ç›®æ ‡åˆ—
        feature_cols = [col for col in data.columns if col != target_col]
        
        numeric_features = []
        categorical_features = []
        
        for col in feature_cols:
            if pd.api.types.is_numeric_dtype(data[col]):
                numeric_features.append(col)
            else:
                # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†ç±»ç‰¹å¾ï¼ˆå­—ç¬¦ä¸²ã€å¯¹è±¡ç±»å‹ï¼Œæˆ–æ•°å€¼ä½†å”¯ä¸€å€¼è¾ƒå°‘ï¼‰
                if data[col].dtype == 'object' or data[col].dtype.name == 'category':
                    categorical_features.append(col)
                elif pd.api.types.is_numeric_dtype(data[col]) and data[col].nunique() <= 10:
                    # æ•°å€¼å‹ä½†å”¯ä¸€å€¼è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯ç¼–ç çš„åˆ†ç±»ç‰¹å¾
                    print(f"å°†æ•°å€¼ç‰¹å¾ '{col}' è§†ä¸ºåˆ†ç±»ç‰¹å¾ï¼ˆå”¯ä¸€å€¼æ•°é‡: {data[col].nunique()}ï¼‰")
                    categorical_features.append(col)
                else:
                    numeric_features.append(col)
        
        # æ‰€æœ‰ç‰¹å¾éƒ½å¯ä»¥ä½œä¸ºåˆ†æ®µå€™é€‰ï¼ˆåˆ†ç±»ç‰¹å¾ç”¨äºåˆ†æ®µï¼Œæ•°å€¼ç‰¹å¾æ—¢å¯åˆ†æ®µä¹Ÿå¯åšå¤šé¡¹å¼ï¼‰
        all_split_candidates = numeric_features + categorical_features
        
        print(f"ç‰¹å¾ç±»å‹è¯†åˆ«:")
        print(f"  æ•°å€¼ç‰¹å¾: {numeric_features}")
        print(f"  åˆ†ç±»ç‰¹å¾: {categorical_features}")
        print(f"  å¯åˆ†æ®µç‰¹å¾: {all_split_candidates}")
        
        return numeric_features, categorical_features, all_split_candidates
        
    def _encode_categorical_features(self, data, categorical_features):
        """
        å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œç¼–ç 
        
        Returns:
            encoded_data: ç¼–ç åçš„æ•°æ®
        """
        encoded_data = data.copy()
        
        for col in categorical_features:
            if col not in self.label_encoders:
                # åˆ›å»ºå¹¶æ‹Ÿåˆæ ‡ç­¾ç¼–ç å™¨
                le = LabelEncoder()
                encoded_data[col] = le.fit_transform(data[col].astype(str))
                self.label_encoders[col] = le
                print(f"å¯¹åˆ†ç±»ç‰¹å¾ '{col}' è¿›è¡Œç¼–ç : {dict(zip(le.classes_, le.transform(le.classes_)))}")
            else:
                # ä½¿ç”¨å·²æœ‰çš„ç¼–ç å™¨
                encoded_data[col] = self.label_encoders[col].transform(data[col].astype(str))
        
        return encoded_data
    
    def _generate_feature_combinations(self, numeric_features, categorical_features, target_col):
        """
        ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç‰¹å¾ç»„åˆ
        
        Args:
            numeric_features: æ•°å€¼ç‰¹å¾åˆ—è¡¨
            categorical_features: åˆ†ç±»ç‰¹å¾åˆ—è¡¨
            target_col: ç›®æ ‡åˆ—å
            
        Returns:
            combinations_list: [(split_features, poly_features), ...]
        """
        # åˆ†æ®µç‰¹å¾å€™é€‰ï¼šæ•°å€¼ç‰¹å¾ + åˆ†ç±»ç‰¹å¾
        split_candidates = numeric_features + categorical_features
        # å¤šé¡¹å¼ç‰¹å¾å€™é€‰ï¼šåªèƒ½æ˜¯æ•°å€¼ç‰¹å¾
        poly_candidates = numeric_features
        
        if len(split_candidates) < 1 or len(poly_candidates) < 1:
            print("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡Œç»„åˆä¼˜åŒ–")
            return [([], poly_candidates)]
        
        combinations_list = []
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åˆ†æ®µç‰¹å¾ç»„åˆ
        for split_size in range(1, min(len(split_candidates), 4) + 1):  # é™åˆ¶åˆ†æ®µç‰¹å¾æœ€å¤š4ä¸ª
            for split_features in combinations(split_candidates, split_size):
                # å¤šé¡¹å¼ç‰¹å¾ï¼šæ•°å€¼ç‰¹å¾ä¸­å»é™¤å·²ç”¨ä½œåˆ†æ®µçš„æ•°å€¼ç‰¹å¾
                available_poly_features = [f for f in poly_candidates if f not in split_features]
                
                # ç¡®ä¿å¤šé¡¹å¼ç‰¹å¾è‡³å°‘æœ‰1ä¸ª
                if len(available_poly_features) >= 1:
                    combinations_list.append((list(split_features), available_poly_features))
        
        # å¦‚æœç»„åˆæ•°é‡å¤ªå¤šï¼Œè¿›è¡Œæ™ºèƒ½ç­›é€‰
        if len(combinations_list) > self.max_combinations:
            print(f"è­¦å‘Š: ç‰¹å¾ç»„åˆæ•°é‡ ({len(combinations_list)}) è¶…è¿‡æœ€å¤§é™åˆ¶ ({self.max_combinations})")
            print("å°†ä½¿ç”¨å¯å‘å¼æ–¹æ³•ç­›é€‰æœ€æœ‰å¸Œæœ›çš„ç»„åˆ...")
            combinations_list = self._select_promising_combinations(combinations_list, split_candidates, poly_candidates)
        
        return combinations_list
    
    def _select_promising_combinations(self, all_combinations, split_candidates, poly_candidates):
        """
        ä½¿ç”¨å¯å‘å¼æ–¹æ³•ç­›é€‰æœ€æœ‰å¸Œæœ›çš„ç‰¹å¾ç»„åˆ
        """
        # ç­–ç•¥1: ä¼˜å…ˆé€‰æ‹©åˆ†æ®µç‰¹å¾æ•°é‡é€‚ä¸­çš„ç»„åˆ (1-2ä¸ªåˆ†æ®µç‰¹å¾)
        moderate_combinations = [combo for combo in all_combinations 
                               if 1 <= len(combo[0]) <= 2]
        
        # ç­–ç•¥2: ä¼˜å…ˆé€‰æ‹©åŒ…å«åˆ†ç±»ç‰¹å¾çš„ç»„åˆï¼ˆåˆ†ç±»ç‰¹å¾é€šå¸¸æ˜¯å¥½çš„åˆ†æ®µç‰¹å¾ï¼‰
        categorical_combinations = [combo for combo in moderate_combinations
                                  if any(f in self.categorical_features for f in combo[0])]
        
        # ç­–ç•¥3: å¦‚æœåˆ†ç±»ç‰¹å¾ç»„åˆä¸å¤Ÿï¼Œè¡¥å……æ•°å€¼ç‰¹å¾ç»„åˆ
        if len(categorical_combinations) < self.max_combinations // 2:
            remaining_combinations = [combo for combo in moderate_combinations 
                                    if combo not in categorical_combinations]
            categorical_combinations.extend(remaining_combinations[:self.max_combinations // 2])
        
        # ç­–ç•¥4: å¦‚æœè¿˜æ˜¯å¤ªå¤šï¼Œéšæœºé‡‡æ ·
        if len(categorical_combinations) > self.max_combinations:
            np.random.seed(42)
            indices = np.random.choice(len(categorical_combinations), 
                                     self.max_combinations, replace=False)
            categorical_combinations = [categorical_combinations[i] for i in indices]
        
        # ç­–ç•¥5: æ€»æ˜¯åŒ…å«ä¸€äº›åŸºå‡†ç»„åˆ
        baseline_combinations = []
        if split_candidates and poly_candidates:
            baseline_combinations = [
                ([split_candidates[0]], poly_candidates),  # ç¬¬ä¸€ä¸ªç‰¹å¾ä½œä¸ºåˆ†æ®µ
            ]
            if len(split_candidates) > 1:
                baseline_combinations.append(([split_candidates[-1]], [f for f in poly_candidates if f != split_candidates[-1]]))
        
        # åˆå¹¶å¹¶å»é‡
        final_combinations = baseline_combinations + categorical_combinations
        seen = set()
        unique_combinations = []
        for combo in final_combinations:
            combo_key = (tuple(sorted(combo[0])), tuple(sorted(combo[1])))
            if combo_key not in seen:
                seen.add(combo_key)
                unique_combinations.append(combo)
        
        return unique_combinations[:self.max_combinations]
    
    def _evaluate_combination(self, data, split_features, poly_features, target_col):
        """
        è¯„ä¼°å•ä¸ªç‰¹å¾ç»„åˆçš„æ•ˆæœ
        
        Returns:
            score: è¯¥ç»„åˆçš„ç»¼åˆè¯„åˆ†
            rules: å‘ç°çš„è§„åˆ™åˆ—è¡¨
        """
        try:
            X_split = data[split_features]
            y_target = data[target_col]
            
            # è®­ç»ƒå†³ç­–æ ‘
            tree_model = DecisionTreeRegressor(
                max_depth=self.max_depth,
                min_samples_leaf=self.min_samples_leaf,
                random_state=42
            )
            
            tree_model.fit(X_split, y_target)
            
            # æå–æ¡ä»¶å’Œåˆ†æ®µ
            conditions_by_leaf = self._extract_tree_conditions(tree_model, split_features, data)
            leaf_ids = tree_model.apply(X_split)
            
            segment_scores = []
            segment_rules = []
            
            # è¯„ä¼°æ¯ä¸ªåˆ†æ®µçš„å¤šé¡¹å¼æ‹Ÿåˆæ•ˆæœ
            for leaf_id, conditions in conditions_by_leaf.items():
                subset_mask = (leaf_ids == leaf_id)
                subset_data = data[subset_mask]
                
                if len(subset_data) < self.min_samples_leaf // 2:
                    continue
                
                X_poly = subset_data[poly_features]
                y_poly = subset_data[target_col]
                
                # ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°å¤šé¡¹å¼æ‹Ÿåˆæ•ˆæœ
                if len(X_poly) >= self.cv_folds and len(poly_features) > 0:
                    try:
                        model = LinearRegression()
                        cv_scores = cross_val_score(model, X_poly, y_poly, 
                                                   cv=min(self.cv_folds, len(X_poly)), 
                                                   scoring='r2')
                        avg_score = np.mean(cv_scores)
                        
                        if avg_score > 0.1:  # æœ€å°è´¨é‡é˜ˆå€¼
                            model.fit(X_poly, y_poly)
                            rule_str = self._format_polynomial_rule(model, poly_features, target_col)
                            condition_str = " ä¸” ".join(conditions)
                            
                            # ğŸ”§ æ–°å¢ï¼šç®€åŒ–æ¡ä»¶å­—ç¬¦ä¸²
                            condition_str = self._simplify_condition_string(condition_str)
                            
                            segment_scores.append(avg_score)
                            segment_rules.append({
                                'split_features': split_features,
                                'poly_features': poly_features,
                                'condition': condition_str,
                                'rule': rule_str,
                                'cv_r2_score': avg_score,
                                'sample_count': len(subset_data),
                                'model': model
                            })
                            
                    except Exception as e:
                        continue
            
            # è®¡ç®—æ•´ä½“è¯„åˆ†ï¼šå¹³å‡RÂ²åˆ†æ•° Ã— è§„åˆ™æ•°é‡æƒé‡
            if segment_scores:
                avg_score = np.mean(segment_scores)
                rule_count_bonus = min(len(segment_scores) / 10, 0.1)  # è§„åˆ™æ•°é‡å¥–åŠ±ï¼Œæœ€å¤§10%
                total_score = avg_score + rule_count_bonus
                return total_score, segment_rules
            else:
                return 0.0, []
                
        except Exception as e:
            return 0.0, []
    
    def _extract_tree_conditions(self, tree_model, feature_names, original_data):
        """
        ä»å†³ç­–æ ‘ä¸­æå–ç²¾ç¡®çš„æ¡ä»¶è·¯å¾„ï¼Œå¹¶å°†ç¼–ç åçš„åˆ†ç±»å€¼è½¬æ¢å›åŸå§‹å€¼
        """
        tree = tree_model.tree_
        conditions_by_leaf = {}
        
        def extract_path(node_id, conditions):
            if tree.children_left[node_id] == -1:  # å¶å­èŠ‚ç‚¹
                conditions_by_leaf[node_id] = conditions.copy()
                return
                
            feature_idx = tree.feature[node_id]
            threshold = tree.threshold[node_id]
            feature_name = feature_names[feature_idx]
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºåˆ†ç±»ç‰¹å¾
            if feature_name in self.categorical_features:
                # åˆ†ç±»ç‰¹å¾ï¼šå°†é˜ˆå€¼è½¬æ¢å›åŸå§‹åˆ†ç±»å€¼
                le = self.label_encoders[feature_name]
                
                # è·å–è¯¥ç‰¹å¾çš„æ‰€æœ‰å¯èƒ½å€¼
                unique_encoded_values = sorted(original_data[feature_name].unique())
                
                # æ ¹æ®é˜ˆå€¼ç¡®å®šåˆ†ç±»æ¡ä»¶
                left_values = [val for val in unique_encoded_values if val <= threshold]
                right_values = [val for val in unique_encoded_values if val > threshold]
                
                # è½¬æ¢å›åŸå§‹åˆ†ç±»å€¼
                if left_values:
                    left_original = [le.inverse_transform([int(val)])[0] for val in left_values]
                    left_condition = f"{feature_name} âˆˆ {{{', '.join(map(str, left_original))}}}"
                else:
                    left_condition = f"{feature_name} âˆˆ {{}}"
                
                if right_values:
                    right_original = [le.inverse_transform([int(val)])[0] for val in right_values]
                    right_condition = f"{feature_name} âˆˆ {{{', '.join(map(str, right_original))}}}"
                else:
                    right_condition = f"{feature_name} âˆˆ {{}}"
                
                # å·¦åˆ†æ”¯
                left_conditions = conditions + [left_condition]
                extract_path(tree.children_left[node_id], left_conditions)
                
                # å³åˆ†æ”¯
                right_conditions = conditions + [right_condition]
                extract_path(tree.children_right[node_id], right_conditions)
            else:
                # æ•°å€¼ç‰¹å¾ï¼šä¿æŒåŸæœ‰é€»è¾‘
                left_conditions = conditions + [f"{feature_name} <= {threshold:.2f}"]
                extract_path(tree.children_left[node_id], left_conditions)
                
                right_conditions = conditions + [f"{feature_name} > {threshold:.2f}"]
                extract_path(tree.children_right[node_id], right_conditions)
        
        extract_path(0, [])
        return conditions_by_leaf
    
    def _format_polynomial_rule(self, model, poly_features, target_col):
        """æ ¼å¼åŒ–å¤šé¡¹å¼è§„åˆ™"""
        coefficients = model.coef_
        intercept = model.intercept_
        
        rule_parts = []
        for i, col_name in enumerate(poly_features):
            coeff_val = coefficients[i]
            
            if abs(coeff_val) < 0.001:  # ç³»æ•°æ¥è¿‘0ï¼Œå¿½ç•¥æ­¤é¡¹
                continue
                
            coeff_rounded = self._smart_round(coeff_val)
            
            if coeff_rounded == 1:
                rule_parts.append(col_name)
            elif coeff_rounded == -1:
                rule_parts.append(f"-{col_name}")
            else:
                rule_parts.append(f"{coeff_rounded} * {col_name}")
        
        intercept_rounded = self._smart_round(intercept)
        
        if not rule_parts:
            return f"{target_col} = {intercept_rounded}"
            
        rule_str = f"{target_col} = {' + '.join(rule_parts)}"
        
        if intercept_rounded != 0:
            if intercept_rounded > 0:
                rule_str += f" + {intercept_rounded}"
            else:
                rule_str += f" - {abs(intercept_rounded)}"
                
        return rule_str
    
    def _smart_round(self, value):
        """æ™ºèƒ½å››èˆäº”å…¥"""
        rounded_int = round(value)
        rounded_dec1 = round(value, 1)
        rounded_dec2 = round(value, 2)
        
        if abs(value - rounded_int) < 0.001:
            return rounded_int
        elif abs(value - rounded_dec1) < 0.001:
            return rounded_dec1
        elif abs(value - rounded_dec2) < 0.001:
            return rounded_dec2
        else:
            return round(value, 4)
    
    def _simplify_condition_string(self, condition_str):
        """
        ç®€åŒ–æ¡ä»¶å­—ç¬¦ä¸²ä¸­çš„å†—ä½™æ¡ä»¶
        
        ä¾‹å¦‚: "x <= 39.50 ä¸” x <= 29.50 ä¸” y âˆˆ {A}" 
        ç®€åŒ–ä¸º: "x <= 29.50 ä¸” y âˆˆ {A}"
        
        Args:
            condition_str: åŸå§‹æ¡ä»¶å­—ç¬¦ä¸²
            
        Returns:
            simplified_str: ç®€åŒ–åçš„æ¡ä»¶å­—ç¬¦ä¸²
        """
        if not condition_str or condition_str.strip() == "":
            return condition_str
            
        # è§£ææ¡ä»¶
        conditions = self._parse_condition(condition_str)
        
        # é‡æ–°æ ¼å¼åŒ–ï¼ˆè¿™ä¼šè‡ªåŠ¨ç®€åŒ–å†—ä½™æ¡ä»¶ï¼‰
        simplified_str = self._format_merged_conditions(conditions)
        
        return simplified_str
    
    def discover_optimal_rules(self, csv_file_path, target_col=None, 
                              manual_split_features=None, manual_poly_features=None):
        """
        å‘ç°æœ€ä¼˜çš„æ¡ä»¶å¤šé¡¹å¼è§„åˆ™
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            target_col: ç›®æ ‡åˆ—åï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æœ€åä¸€åˆ—
            manual_split_features: æ‰‹åŠ¨æŒ‡å®šçš„åˆ†æ®µç‰¹å¾
            manual_poly_features: æ‰‹åŠ¨æŒ‡å®šçš„å¤šé¡¹å¼ç‰¹å¾
            
        Returns:
            best_rules: æœ€ä¼˜è§„åˆ™åˆ—è¡¨
        """
        try:
            print("=== ä¼˜åŒ–ç‰ˆæ¡ä»¶è§„åˆ™å‘ç°ï¼ˆæ”¯æŒåˆ†ç±»ç‰¹å¾ï¼‰===")
            start_time = time.time()
            
            # 1. æ•°æ®åŠ è½½
            data = pd.read_csv(csv_file_path)
            print(f"æˆåŠŸåŠ è½½æ•°æ®: {csv_file_path}")
            print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
            
            # 2. ç¡®å®šç›®æ ‡åˆ—
            if target_col is None:
                target_col = data.columns[-1]
                print(f"è‡ªåŠ¨é€‰æ‹©æœ€åä¸€åˆ— '{target_col}' ä½œä¸ºç›®æ ‡åˆ—")
            
            # 3. è¯†åˆ«ç‰¹å¾ç±»å‹
            numeric_features, categorical_features, all_split_candidates = self._identify_feature_types(data, target_col)
            self.categorical_features = categorical_features
            
            if len(all_split_candidates) < 1 or len(numeric_features) < 1:
                print("é”™è¯¯: æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡Œåˆ†æ")
                return []
            
            # 4. å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œç¼–ç 
            encoded_data = self._encode_categorical_features(data, categorical_features)
            
            # 5. ç‰¹å¾ç»„åˆç­–ç•¥
            if manual_split_features is not None and manual_poly_features is not None:
                # ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„ç‰¹å¾ç»„åˆ
                combinations_to_try = [(manual_split_features, manual_poly_features)]
                print(f"ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„ç‰¹å¾ç»„åˆ")
            elif self.enable_exhaustive_search:
                # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç‰¹å¾ç»„åˆ
                combinations_to_try = self._generate_feature_combinations(numeric_features, categorical_features, target_col)
                print(f"ç”Ÿæˆ {len(combinations_to_try)} ä¸ªç‰¹å¾ç»„åˆè¿›è¡Œç©·ä¸¾æœç´¢")
            else:
                # ä½¿ç”¨å¯å‘å¼æ–¹æ³•ç”Ÿæˆå°‘é‡é«˜è´¨é‡ç»„åˆ
                all_combinations = self._generate_feature_combinations(numeric_features, categorical_features, target_col)
                combinations_to_try = self._select_promising_combinations(all_combinations, all_split_candidates, numeric_features)
                print(f"ä½¿ç”¨å¯å‘å¼æ–¹æ³•é€‰æ‹© {len(combinations_to_try)} ä¸ªç‰¹å¾ç»„åˆ")
            
            # 6. è¯„ä¼°æ‰€æœ‰ç»„åˆ
            print("\nğŸ” å¼€å§‹è¯„ä¼°ç‰¹å¾ç»„åˆ...")
            best_score = -1
            best_rules = []
            progress_interval = max(1, len(combinations_to_try) // 10)
            
            for i, (split_features, poly_features) in enumerate(combinations_to_try):
                # åªåœ¨å…³é”®è¿›åº¦ç‚¹æ˜¾ç¤ºä¿¡æ¯
                if i % progress_interval == 0 or i == len(combinations_to_try) - 1:
                    progress = (i + 1) / len(combinations_to_try) * 100
                    print(f"   è¿›åº¦: {progress:.1f}% ({i+1}/{len(combinations_to_try)}) - å½“å‰æœ€ä½³åˆ†æ•°: {best_score:.3f}")
                
                score, rules = self._evaluate_combination(encoded_data, split_features, poly_features, target_col)
                
                if score > best_score:
                    previous_score = best_score
                    best_score = score
                    best_rules = rules
                    self.best_configuration = {
                        'split_features': split_features,
                        'poly_features': poly_features,
                        'score': score,
                        'num_rules': len(rules)
                    }
                    
                    # åªåœ¨æ‰¾åˆ°æ˜æ˜¾æ›´å¥½çš„ç»„åˆæ—¶æ‰è¾“å‡º
                    if previous_score <= 0 or score > previous_score * 1.05:  # æå‡è¶…è¿‡5%æ‰æŠ¥å‘Š
                        print(f"   âœ¨ å‘ç°æ›´ä¼˜ç»„åˆ! åˆ†æ®µç‰¹å¾: {split_features}")
                        print(f"      å¤šé¡¹å¼ç‰¹å¾: {poly_features}")
                        print(f"      è¯„åˆ†æå‡: {score:.3f} (ä¹‹å‰: {previous_score:.3f})")
            
            # 7. è¾“å‡ºç»“æœ
            elapsed_time = time.time() - start_time
            print(f"\nâœ… æœç´¢å®Œæˆ! è€—æ—¶: {elapsed_time:.2f}ç§’")
            
            if best_rules:
                print(f"\nğŸ† æœ€ä¼˜ç‰¹å¾é…ç½®:")
                print(f"   ğŸ”§ åˆ†æ®µç‰¹å¾: {self.best_configuration['split_features']}")
                print(f"   ğŸ“Š å¤šé¡¹å¼ç‰¹å¾: {self.best_configuration['poly_features']}")
                print(f"   ğŸ“ˆ ç»¼åˆè¯„åˆ†: {self.best_configuration['score']:.3f}")
                print(f"   ğŸ“‹ å‘ç°è§„åˆ™æ•°: {self.best_configuration['num_rules']}")
                
                self._display_optimal_results(best_rules)
            else:
                print("âŒ æœªå‘ç°æœ‰æ•ˆçš„æ¡ä»¶è§„åˆ™")
                print("ğŸ’¡ å»ºè®®:")
                print("   â€¢ å°è¯•å‡å° --min-samples å‚æ•°")
                print("   â€¢ å°è¯•å¢å¤§ --max-depth å‚æ•°")
                print("   â€¢ æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„æ•°å€¼ç‰¹å¾")
            
            return best_rules
            
        except FileNotFoundError:
            print(f"é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° {csv_file_path}")
            return []
        except Exception as e:
            print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _display_optimal_results(self, rules):
        """æ˜¾ç¤ºæœ€ä¼˜ç»“æœ"""
        if not rules:
            print("\næœªå‘ç°ä»»ä½•æœ‰æ•ˆè§„åˆ™")
            return
            
        print(f"\n{'='*50} æœ€ä¼˜è§„åˆ™è¯¦æƒ… {'='*50}")
        
        # æŒ‰äº¤å‰éªŒè¯RÂ²åˆ†æ•°æ’åºï¼Œå»é‡
        unique_rules = []
        seen_rules = set()
        
        for rule in rules:
            rule_key = (rule['condition'], rule['rule'])
            if rule_key not in seen_rules:
                seen_rules.add(rule_key)
                unique_rules.append(rule)
        
        sorted_rules = sorted(unique_rules, key=lambda x: x['cv_r2_score'], reverse=True)
        
        # æ˜¾ç¤ºè¯¦ç»†è§„åˆ™ä¿¡æ¯
        for i, rule in enumerate(sorted_rules, 1):
            print(f"\nè§„åˆ™ {i}:")
            print(f"  æ¡ä»¶: {rule['condition']}")
            print(f"  è§„åˆ™: {rule['rule']}")
            print(f"  äº¤å‰éªŒè¯RÂ²: {rule['cv_r2_score']:.3f}")
            print(f"  æ ·æœ¬æ•°: {rule['sample_count']}")
            if i < len(sorted_rules):  # ä¸æ˜¯æœ€åä¸€ä¸ªè§„åˆ™
                print("  " + "-" * 60)
        
        # ç”Ÿæˆæ¸…æ™°çš„è¡¨æ ¼æ€»ç»“
        print(f"\n{'='*50} æœ€ä¼˜è§„åˆ™æ±‡æ€»è¡¨ {'='*50}")
        
        # åŠ¨æ€è°ƒæ•´åˆ—å®½
        max_condition_len = min(50, max(len(rule['condition']) for rule in sorted_rules) + 2)
        max_rule_len = min(40, max(len(rule['rule']) for rule in sorted_rules) + 2)
        
        # æ‰“å°è¡¨å¤´
        header = f"| {'æ’å':^4} | {'æ¡ä»¶':^{max_condition_len}} | {'è§„åˆ™':^{max_rule_len}} | {'RÂ²':^5} | {'æ ·æœ¬æ•°':^6} |"
        separator = "|" + "-" * 6 + "|" + "-" * (max_condition_len + 2) + "|" + "-" * (max_rule_len + 2) + "|" + "-" * 7 + "|" + "-" * 8 + "|"
        
        print(separator)
        print(header)
        print(separator)
        
        # æ‰“å°è§„åˆ™è¡Œ
        for i, rule in enumerate(sorted_rules, 1):
            condition = rule['condition']
            if len(condition) > max_condition_len:
                condition = condition[:max_condition_len-3] + "..."
                
            rule_str = rule['rule']
            if len(rule_str) > max_rule_len:
                rule_str = rule_str[:max_rule_len-3] + "..."
            
            row = f"| {i:^4} | {condition:<{max_condition_len}} | {rule_str:<{max_rule_len}} | {rule['cv_r2_score']:^5.3f} | {rule['sample_count']:^6} |"
            print(row)
        
        print(separator)
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š åŸå§‹è§„åˆ™ç»Ÿè®¡:")
        print(f"   â€¢ æ€»è§„åˆ™æ•°: {len(sorted_rules)}")
        print(f"   â€¢ å¹³å‡RÂ²åˆ†æ•°: {np.mean([r['cv_r2_score'] for r in sorted_rules]):.3f}")
        print(f"   â€¢ è¦†ç›–æ ·æœ¬æ€»æ•°: {sum(r['sample_count'] for r in sorted_rules)}")
        
        # è´¨é‡åˆ†çº§ç»Ÿè®¡
        excellent_rules = [r for r in sorted_rules if r['cv_r2_score'] >= 0.9]
        good_rules = [r for r in sorted_rules if 0.7 <= r['cv_r2_score'] < 0.9]
        fair_rules = [r for r in sorted_rules if r['cv_r2_score'] < 0.7]
        
        print(f"   â€¢ ä¼˜ç§€è§„åˆ™(RÂ²â‰¥0.9): {len(excellent_rules)}æ¡")
        print(f"   â€¢ è‰¯å¥½è§„åˆ™(0.7â‰¤RÂ²<0.9): {len(good_rules)}æ¡") 
        print(f"   â€¢ ä¸€èˆ¬è§„åˆ™(RÂ²<0.7): {len(fair_rules)}æ¡")
        
        # ğŸ”— æ™ºèƒ½åˆå¹¶ç›¸åŒè§„åˆ™
        merged_rules = self._merge_similar_rules(sorted_rules)
        
        if len(merged_rules) < len(sorted_rules):
            # æ˜¾ç¤ºåˆå¹¶åçš„ç»“æœ
            print(f"\n{'='*50} æ™ºèƒ½åˆå¹¶åè§„åˆ™ {'='*50}")
            
            # é‡æ–°è®¡ç®—åˆå¹¶åè§„åˆ™çš„è¡¨æ ¼å®½åº¦
            merged_max_condition_len = min(60, max(len(rule['condition']) for rule in merged_rules) + 2)
            merged_max_rule_len = min(40, max(len(rule['rule']) for rule in merged_rules) + 2)
            
            # åˆå¹¶åè¡¨æ ¼
            merged_header = f"| {'æ’å':^4} | {'æ¡ä»¶':^{merged_max_condition_len}} | {'è§„åˆ™':^{merged_max_rule_len}} | {'RÂ²':^5} | {'æ ·æœ¬æ•°':^6} | {'åˆå¹¶æ•°':^6} |"
            merged_separator = "|" + "-" * 6 + "|" + "-" * (merged_max_condition_len + 2) + "|" + "-" * (merged_max_rule_len + 2) + "|" + "-" * 7 + "|" + "-" * 8 + "|" + "-" * 8 + "|"
            
            print(merged_separator)
            print(merged_header)
            print(merged_separator)
            
            # æŒ‰RÂ²é‡æ–°æ’åºåˆå¹¶åçš„è§„åˆ™
            merged_sorted = sorted(merged_rules, key=lambda x: x['cv_r2_score'], reverse=True)
            
            for i, rule in enumerate(merged_sorted, 1):
                condition = rule['condition']
                if len(condition) > merged_max_condition_len:
                    condition = condition[:merged_max_condition_len-3] + "..."
                    
                rule_str = rule['rule']
                if len(rule_str) > merged_max_rule_len:
                    rule_str = rule_str[:merged_max_rule_len-3] + "..."
                
                merge_info = f"{rule.get('merged_from', 1)}" if 'merged_from' in rule else "1"
                
                row = f"| {i:^4} | {condition:<{merged_max_condition_len}} | {rule_str:<{merged_max_rule_len}} | {rule['cv_r2_score']:^5.3f} | {rule['sample_count']:^6} | {merge_info:^6} |"
                print(row)
            
            print(merged_separator)
            
            # åˆå¹¶åç»Ÿè®¡
            print(f"\nğŸ“Š åˆå¹¶åè§„åˆ™ç»Ÿè®¡:")
            print(f"   â€¢ åˆå¹¶åè§„åˆ™æ•°: {len(merged_rules)} (å‡å°‘äº† {len(sorted_rules) - len(merged_rules)} æ¡)")
            print(f"   â€¢ å¹³å‡RÂ²åˆ†æ•°: {np.mean([r['cv_r2_score'] for r in merged_rules]):.3f}")
            print(f"   â€¢ è¦†ç›–æ ·æœ¬æ€»æ•°: {sum(r['sample_count'] for r in merged_rules)}")
            
            # çªå‡ºæ˜¾ç¤ºç®€åŒ–æ•ˆæœ
            simplification_rate = (len(sorted_rules) - len(merged_rules)) / len(sorted_rules) * 100
            print(f"   ğŸ¯ è§„åˆ™ç®€åŒ–ç‡: {simplification_rate:.1f}%")
            
            # ğŸ’¾ ä¿å­˜å‘ç°çš„è§„åˆ™ä¾›é¢„æµ‹å™¨ä½¿ç”¨
            self.discovered_rules = merged_rules
            print(f"\nâœ… è§„åˆ™å·²ä¿å­˜åˆ°å‘ç°å™¨ï¼Œå¯ç”¨äºåç»­é¢„æµ‹")
            
        else:
            print(f"\nğŸ’¡ æ‰€æœ‰è§„åˆ™éƒ½æ˜¯å”¯ä¸€çš„ï¼Œæ— éœ€åˆå¹¶")
            # ğŸ’¾ ä¿å­˜å‘ç°çš„è§„åˆ™ä¾›é¢„æµ‹å™¨ä½¿ç”¨
            self.discovered_rules = sorted_rules
            print(f"\nâœ… è§„åˆ™å·²ä¿å­˜åˆ°å‘ç°å™¨ï¼Œå¯ç”¨äºåç»­é¢„æµ‹")
            
        return merged_rules if len(merged_rules) < len(sorted_rules) else sorted_rules
    
    def _merge_similar_rules(self, rules):
        """
        åˆå¹¶ç›¸åŒè§„åˆ™çš„æ¡ä»¶
        
        Args:
            rules: è§„åˆ™åˆ—è¡¨
            
        Returns:
            merged_rules: åˆå¹¶åçš„è§„åˆ™åˆ—è¡¨
        """
        if not rules:
            return []
            
        print(f"\nğŸ”— å¼€å§‹æ™ºèƒ½åˆå¹¶ç›¸åŒè§„åˆ™...")
        
        # æŒ‰è§„åˆ™å†…å®¹åˆ†ç»„
        rule_groups = {}
        for rule in rules:
            rule_formula = rule['rule']
            if rule_formula not in rule_groups:
                rule_groups[rule_formula] = []
            rule_groups[rule_formula].append(rule)
        
        merged_rules = []
        merge_count = 0
        
        for rule_formula, group_rules in rule_groups.items():
            if len(group_rules) == 1:
                # åªæœ‰ä¸€ä¸ªè§„åˆ™ï¼Œç›´æ¥ä¿ç•™
                merged_rules.append(group_rules[0])
            else:
                # å¤šä¸ªè§„åˆ™éœ€è¦åˆå¹¶
                print(f"   åˆå¹¶è§„åˆ™: {rule_formula}")
                print(f"   åŸæœ‰ {len(group_rules)} ä¸ªæ¡ä»¶ï¼Œå°è¯•åˆå¹¶...")
                
                merged_rule = self._merge_conditions(group_rules, rule_formula)
                merged_rules.append(merged_rule)
                merge_count += len(group_rules) - 1
                
                print(f"   âœ… åˆå¹¶å®Œæˆï¼Œæ¡ä»¶: {merged_rule['condition']}")
        
        print(f"ğŸ¯ åˆå¹¶ç»Ÿè®¡: åŸæœ‰ {len(rules)} æ¡è§„åˆ™ï¼Œåˆå¹¶å {len(merged_rules)} æ¡è§„åˆ™ï¼Œå…±åˆå¹¶äº† {merge_count} æ¡")
        return merged_rules
    
    def _merge_conditions(self, group_rules, rule_formula):
        """
        åˆå¹¶ä¸€ç»„ç›¸åŒè§„åˆ™çš„æ¡ä»¶
        
        Args:
            group_rules: ç›¸åŒè§„åˆ™çš„åˆ—è¡¨
            rule_formula: è§„åˆ™å…¬å¼
            
        Returns:
            merged_rule: åˆå¹¶åçš„è§„åˆ™
        """
        # è§£ææ‰€æœ‰æ¡ä»¶
        all_conditions = []
        total_samples = 0
        total_r2_weighted = 0
        
        for rule in group_rules:
            conditions = self._parse_condition(rule['condition'])
            all_conditions.append(conditions)
            total_samples += rule['sample_count']
            total_r2_weighted += rule['cv_r2_score'] * rule['sample_count']
        
        # è®¡ç®—åŠ æƒå¹³å‡RÂ²
        avg_r2 = total_r2_weighted / total_samples if total_samples > 0 else 0
        
        # åˆå¹¶æ¡ä»¶
        merged_conditions = self._merge_condition_logic(all_conditions)
        merged_condition_str = self._format_merged_conditions(merged_conditions)
        
        return {
            'condition': merged_condition_str,
            'rule': rule_formula,
            'cv_r2_score': avg_r2,
            'sample_count': total_samples,
            'merged_from': len(group_rules)
        }
    
    def _parse_condition(self, condition_str):
        """
        è§£ææ¡ä»¶å­—ç¬¦ä¸²ä¸ºç»“æ„åŒ–æ ¼å¼
        
        Args:
            condition_str: æ¡ä»¶å­—ç¬¦ä¸²ï¼Œå¦‚ "x <= 39.50 ä¸” y âˆˆ {y1}"
            
        Returns:
            conditions: è§£æåçš„æ¡ä»¶å­—å…¸
        """
        conditions = {}
        
        # æŒ‰ "ä¸”" åˆ†å‰²æ¡ä»¶
        parts = condition_str.split(' ä¸” ')
        
        for part in parts:
            part = part.strip()
            
            if ' âˆˆ ' in part:
                # åˆ†ç±»æ¡ä»¶ï¼šy âˆˆ {y1, y2}
                feature, values_str = part.split(' âˆˆ ')
                feature = feature.strip()
                # æå–é›†åˆä¸­çš„å€¼
                values_str = values_str.strip().replace('{', '').replace('}', '')
                values = [v.strip() for v in values_str.split(',')]
                
                if feature not in conditions:
                    conditions[feature] = {'type': 'categorical', 'values': set()}
                conditions[feature]['values'].update(values)
                
            elif '<=' in part:
                # æ•°å€¼æ¡ä»¶ï¼šx <= 39.50
                feature, value_str = part.split('<=')
                feature = feature.strip()
                value = float(value_str.strip())
                
                if feature not in conditions:
                    conditions[feature] = {'type': 'numeric', 'upper': None, 'lower': None}
                
                if conditions[feature]['upper'] is None or value < conditions[feature]['upper']:
                    conditions[feature]['upper'] = value
                    
            elif '>' in part:
                # æ•°å€¼æ¡ä»¶ï¼šx > 39.50
                feature, value_str = part.split('>')
                feature = feature.strip()
                value = float(value_str.strip())
                
                if feature not in conditions:
                    conditions[feature] = {'type': 'numeric', 'upper': None, 'lower': None}
                
                if conditions[feature]['lower'] is None or value > conditions[feature]['lower']:
                    conditions[feature]['lower'] = value
        
        return conditions
    
    def _merge_condition_logic(self, all_conditions):
        """
        åˆå¹¶å¤šä¸ªæ¡ä»¶çš„é€»è¾‘
        
        Args:
            all_conditions: å¤šä¸ªæ¡ä»¶çš„åˆ—è¡¨
            
        Returns:
            merged_conditions: åˆå¹¶åçš„æ¡ä»¶
        """
        merged = {}
        
        # æ”¶é›†æ‰€æœ‰ç‰¹å¾
        all_features = set()
        for conditions in all_conditions:
            all_features.update(conditions.keys())
        
        for feature in all_features:
            feature_conditions = []
            
            # æ”¶é›†è¯¥ç‰¹å¾çš„æ‰€æœ‰æ¡ä»¶
            for conditions in all_conditions:
                if feature in conditions:
                    feature_conditions.append(conditions[feature])
            
            if not feature_conditions:
                continue
                
            first_condition = feature_conditions[0]
            
            if first_condition['type'] == 'categorical':
                # åˆ†ç±»ç‰¹å¾ï¼šå–å¹¶é›†
                all_values = set()
                for cond in feature_conditions:
                    all_values.update(cond['values'])
                
                merged[feature] = {
                    'type': 'categorical',
                    'values': all_values
                }
                
            elif first_condition['type'] == 'numeric':
                # æ•°å€¼ç‰¹å¾ï¼šè®¡ç®—çœŸæ­£çš„å¹¶é›†èŒƒå›´
                ranges = []
                
                # æ”¶é›†æ‰€æœ‰çš„æ•°å€¼èŒƒå›´
                for cond in feature_conditions:
                    upper = cond.get('upper')
                    lower = cond.get('lower')
                    
                    # æ„å»ºèŒƒå›´å…ƒç»„ (lower_bound, upper_bound, inclusive_lower, inclusive_upper)
                    if upper is not None and lower is not None:
                        # å½¢å¦‚ lower < x <= upper
                        ranges.append((lower, upper, False, True))
                    elif upper is not None:
                        # å½¢å¦‚ x <= upperï¼Œç›¸å½“äº (-âˆ, upper]
                        ranges.append((float('-inf'), upper, True, True))
                    elif lower is not None:
                        # å½¢å¦‚ x > lowerï¼Œç›¸å½“äº (lower, +âˆ)
                        ranges.append((lower, float('inf'), False, True))
                
                # åˆå¹¶é‡å çš„èŒƒå›´
                if ranges:
                    merged_range = self._merge_numeric_ranges(ranges)
                    
                    # å°†åˆå¹¶åçš„èŒƒå›´è½¬æ¢å›æ¡ä»¶æ ¼å¼
                    if len(merged_range) == 1:
                        lower, upper, incl_lower, incl_upper = merged_range[0]
                        
                        final_condition = {'type': 'numeric', 'upper': None, 'lower': None}
                        
                        if lower != float('-inf'):
                            final_condition['lower'] = lower
                        if upper != float('inf'):
                            final_condition['upper'] = upper
                            
                        merged[feature] = final_condition
                    else:
                        # å¤šä¸ªä¸è¿ç»­çš„èŒƒå›´ï¼Œæš‚æ—¶å–ç¬¬ä¸€ä¸ªèŒƒå›´ï¼ˆå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ï¼‰
                        lower, upper, incl_lower, incl_upper = merged_range[0]
                        final_condition = {'type': 'numeric', 'upper': None, 'lower': None}
                        
                        if lower != float('-inf'):
                            final_condition['lower'] = lower
                        if upper != float('inf'):
                            final_condition['upper'] = upper
                            
                        merged[feature] = final_condition
        
        return merged
    
    def _merge_numeric_ranges(self, ranges):
        """
        åˆå¹¶æ•°å€¼èŒƒå›´
        
        Args:
            ranges: èŒƒå›´åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (lower, upper, incl_lower, incl_upper)
            
        Returns:
            merged_ranges: åˆå¹¶åçš„èŒƒå›´åˆ—è¡¨
        """
        if not ranges:
            return []
        
        # æ’åºèŒƒå›´
        sorted_ranges = sorted(ranges, key=lambda x: (x[0], x[1]))
        
        merged = [sorted_ranges[0]]
        
        for current in sorted_ranges[1:]:
            last = merged[-1]
            
            # æ£€æŸ¥æ˜¯å¦é‡å æˆ–ç›¸é‚»
            if current[0] <= last[1]:  # æœ‰é‡å 
                # åˆå¹¶èŒƒå›´
                new_lower = min(last[0], current[0])
                new_upper = max(last[1], current[1])
                merged[-1] = (new_lower, new_upper, True, True)
            else:
                # æ²¡æœ‰é‡å ï¼Œæ·»åŠ æ–°èŒƒå›´
                merged.append(current)
        
        return merged
    
    def _format_merged_conditions(self, merged_conditions):
        """
        æ ¼å¼åŒ–åˆå¹¶åçš„æ¡ä»¶
        
        Args:
            merged_conditions: åˆå¹¶åçš„æ¡ä»¶å­—å…¸
            
        Returns:
            condition_str: æ ¼å¼åŒ–çš„æ¡ä»¶å­—ç¬¦ä¸²
        """
        condition_parts = []
        
        for feature, condition in merged_conditions.items():
            if condition['type'] == 'categorical':
                values_str = ', '.join(sorted(condition['values']))
                condition_parts.append(f"{feature} âˆˆ {{{values_str}}}")
                
            elif condition['type'] == 'numeric':
                if condition['lower'] is not None and condition['upper'] is not None:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ„ä¹‰çš„èŒƒå›´
                    if condition['lower'] >= condition['upper']:
                        # è¿™ç§æƒ…å†µä¸‹ï¼Œä¿ç•™æ›´å®½æ³›çš„æ¡ä»¶
                        if abs(condition['lower']) > abs(condition['upper']):
                            condition_parts.append(f"{feature} > {condition['lower']:.2f}")
                        else:
                            condition_parts.append(f"{feature} <= {condition['upper']:.2f}")
                    else:
                        condition_parts.append(f"{condition['lower']:.2f} < {feature} <= {condition['upper']:.2f}")
                elif condition['upper'] is not None:
                    condition_parts.append(f"{feature} <= {condition['upper']:.2f}")
                elif condition['lower'] is not None:
                    condition_parts.append(f"{feature} > {condition['lower']:.2f}")
        
        return ' ä¸” '.join(condition_parts)

def discover_optimal_conditional_rules(csv_file_path, target_col=None,
                                      manual_split_features=None, manual_poly_features=None,
                                      max_depth=3, min_samples_leaf=50, 
                                      enable_exhaustive_search=True, max_combinations=100):
    """
    ä¼˜åŒ–ç‰ˆæ¡ä»¶å¤šé¡¹å¼è§„åˆ™å‘ç°å‡½æ•°
    
    Args:
        csv_file_path: CSVæ–‡ä»¶è·¯å¾„
        target_col: ç›®æ ‡åˆ—åï¼Œé»˜è®¤ä½¿ç”¨æœ€åä¸€åˆ—
        manual_split_features: æ‰‹åŠ¨æŒ‡å®šåˆ†æ®µç‰¹å¾
        manual_poly_features: æ‰‹åŠ¨æŒ‡å®šå¤šé¡¹å¼ç‰¹å¾
        max_depth: å†³ç­–æ ‘æœ€å¤§æ·±åº¦
        min_samples_leaf: å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
        enable_exhaustive_search: æ˜¯å¦å¯ç”¨ç©·ä¸¾æœç´¢
        max_combinations: æœ€å¤§å°è¯•çš„ç»„åˆæ•°
        
    Returns:
        æœ€ä¼˜è§„åˆ™åˆ—è¡¨
    """
    discoverer = OptimalConditionalRuleDiscoverer(
        max_depth=max_depth,
        min_samples_leaf=min_samples_leaf,
        enable_exhaustive_search=enable_exhaustive_search,
        max_combinations=max_combinations
    )
    
    return discoverer.discover_optimal_rules(
        csv_file_path=csv_file_path,
        target_col=target_col,
        manual_split_features=manual_split_features,
        manual_poly_features=manual_poly_features
    )

if __name__ == "__main__":
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆæ¡ä»¶å¤šé¡¹å¼è§„åˆ™å‘ç°å·¥å…·')
    parser.add_argument('csv_file', type=str, help='è¦åˆ†æçš„CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--target-col', type=str, help='ç›®æ ‡åˆ—çš„åç§°ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨æœ€åä¸€åˆ—')
    parser.add_argument('--split-features', type=str, nargs='+', help='æ‰‹åŠ¨æŒ‡å®šåˆ†æ®µç‰¹å¾')
    parser.add_argument('--poly-features', type=str, nargs='+', help='æ‰‹åŠ¨æŒ‡å®šå¤šé¡¹å¼ç‰¹å¾')
    parser.add_argument('--max-depth', type=int, default=3, help='å†³ç­–æ ‘æœ€å¤§æ·±åº¦')
    parser.add_argument('--min-samples', type=int, default=50, help='å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°')
    parser.add_argument('--max-combinations', type=int, default=100, help='æœ€å¤§å°è¯•çš„ç‰¹å¾ç»„åˆæ•°')
    parser.add_argument('--disable-exhaustive', action='store_true', help='ç¦ç”¨ç©·ä¸¾æœç´¢ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•')
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    print("ğŸš€ === ä¼˜åŒ–ç‰ˆæ¡ä»¶è§„åˆ™å‘ç°å·¥å…· === ğŸš€")
    print("ä¸»è¦ç‰¹æ€§:")
    print("  âœ“ æ™ºèƒ½ç‰¹å¾ç»„åˆç©·ä¸¾")
    print("  âœ“ äº¤å‰éªŒè¯è¯„ä¼°æœ€ä¼˜ç»„åˆ")
    print("  âœ“ å¯å‘å¼æœç´¢ä¼˜åŒ–")
    print("  âœ“ åŠ¨æ€ç‰¹å¾åˆ†é…")
    print("  âœ“ æ”¯æŒåˆ†ç±»å’Œæ•°å€¼ç‰¹å¾")
    print("-" * 60)
    
    # è¿è¡Œä¼˜åŒ–ç‰ˆè§„åˆ™å‘ç°
    try:
        rules = discover_optimal_conditional_rules(
            csv_file_path=args.csv_file,
            target_col=args.target_col,
            manual_split_features=args.split_features,
            manual_poly_features=args.poly_features,
            max_depth=args.max_depth,
            min_samples_leaf=args.min_samples,
            enable_exhaustive_search=not args.disable_exhaustive,
            max_combinations=args.max_combinations
        )
        
        # æœ€ç»ˆæ€»ç»“
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"   ğŸ“‹ æœ€ç»ˆå‘ç°çš„æœ€ä¼˜è§„åˆ™æ•°é‡: {len(rules)}")
        
        if rules:
            avg_quality = np.mean([r['cv_r2_score'] for r in rules])
            print(f"   ğŸ“ˆ è§„åˆ™å¹³å‡è´¨é‡(RÂ²): {avg_quality:.3f}")
            if avg_quality >= 0.9:
                print("   ğŸŒŸ è§„åˆ™è´¨é‡: ä¼˜ç§€")
            elif avg_quality >= 0.7:
                print("   â­ è§„åˆ™è´¨é‡: è‰¯å¥½") 
            else:
                print("   ğŸ“Š è§„åˆ™è´¨é‡: ä¸€èˆ¬")
        else:
            print("   âš ï¸  å»ºè®®: å°è¯•è°ƒæ•´å‚æ•°æˆ–æ£€æŸ¥æ•°æ®è´¨é‡")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 
        
    print("\n" + "="*60)
    print("æ„Ÿè°¢ä½¿ç”¨æ¡ä»¶è§„åˆ™å‘ç°å·¥å…·! ğŸ™") 